{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrangian Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T06:23:38.079319Z",
     "start_time": "2020-10-07T06:23:38.074345Z"
    }
   },
   "source": [
    "$$c = \\sqrt{a^2 + b^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T07:48:32.084450Z",
     "start_time": "2020-10-07T07:48:31.900352Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network with 4 layers and h_dim hidden dimension. Custom weight initialization for the LNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T07:51:13.461101Z",
     "start_time": "2020-10-07T07:51:13.455522Z"
    }
   },
   "outputs": [],
   "source": [
    "class LNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        h_dim = 500\n",
    "        self.fc1 =l1= nn.Linear(4, h_dim)\n",
    "        nn.init.normal_(l1.weight ,0, 2.2/np.sqrt(h_dim))\n",
    "        nn.init.constant_(l1.bias, 0)\n",
    "        self.fc2 =l2= nn.Linear(h1_dim,h2_dim)\n",
    "        nn.init.constant_(l2.bias, 0)\n",
    "        nn.init.normal_(l2.weight, 0, 0.58/np.sqrt(h_dim))\n",
    "        self.fc3 =l3= nn.Linear(h_dim,h_dim)\n",
    "        nn.init.normal_(l2.weight, 0, 0.58/np.sqrt(h_dim))\n",
    "        nn.init.normal_(l3.weight, 0, (0.58*2)/np.sqrt(h_dim))\n",
    "        self.fc_last=l4 = nn.Linear(h_dim,1)\n",
    "        nn.init.constant_(l3.bias, 0)\n",
    "        nn.init.normal_(l3.weight, 0, h1_dim/np.sqrt(h_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Flow\n",
    " Output corresponds to the next state correspondent to the generalized positions and velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            qqd = x.requires_grad_(True)\n",
    "            time_step = torch.tensor(0.01)\n",
    "            out=self._rk4_step(qqd,time_step)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T08:03:02.627597Z",
     "start_time": "2020-10-07T08:03:02.621396Z"
    }
   },
   "source": [
    "##  Euler-Lagrange Equations\n",
    "Euler-Lagrange equations propagated by the chain rule to expand the time derivative $\\frac{d}{dt}$ through the gradient. Despite way slower one makes use of the pseudo-inverse (Mooreâ€“Penrose inverse) to avoid Non singular matrices provided by the neural network, and hence not invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T08:00:41.270356Z",
     "start_time": "2020-10-07T08:00:41.263349Z"
    }
   },
   "outputs": [],
   "source": [
    " def euler_lagrange(self,qqd):\n",
    "        self.n = n = qqd.shape[1]//2\n",
    "        L = self._lagrangian(qqd).sum()\n",
    "        J = grad(L, qqd, create_graph=True)[0] ;\n",
    "        DL_q, DL_qd = J[:,:n], J[:,n:]\n",
    "        DDL_qd = []\n",
    "        for i in range(n):\n",
    "            J_qd_i = DL_qd[:,i][:,None]\n",
    "            H_i = grad(J_qd_i.sum(), qqd, create_graph=True)[0][:,:,None]\n",
    "            DDL_qd.append(H_i)\n",
    "        DDL_qd = torch.cat(DDL_qd, 2)\n",
    "        DDL_qqd, DDL_qdqd = DDL_qd[:,:n,:], DDL_qd[:,n:,:]\n",
    "        T = torch.einsum('ijk, ij -> ik', DDL_qqd, qqd[:,n:])\n",
    "        qdd = torch.einsum('ijk, ij -> ik', DDL_qdqd.pinverse(), DL_q - T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrangian\n",
    "Replace the Lagrangian by a parametric model. Here softplus is chosen since it yields better results. The activation function isnotapplied to the last layer in order to avoid constraints to the in the ouput values. ReLuis not used since we make use of the hessian and this one yields zero-second-order derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _lagrangian(self, qqd):\n",
    "        x = F.softplus(self.fc1(qqd))\n",
    "        x = F.softplus(self.fc2(x))\n",
    "        x = F.softplus(self.fc3(x))\n",
    "        L = self.fc_last(x)\n",
    "        return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization     \n",
    "One step of Runge-Kutta-4 integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _rk4_step(self, qqd, h=None):\n",
    "        k1 = h * self.function(qqd)\n",
    "        k2 = h * self.function(qqd + k1/2)\n",
    "        k3 = h * self.function(qqd + k2/2)\n",
    "        k4 = h *self.function(qqd + k3)\n",
    "        return qqd + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Black-Box Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T08:15:29.170721Z",
     "start_time": "2020-10-07T08:15:29.166428Z"
    }
   },
   "outputs": [],
   "source": [
    "class Baseline_FF_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        h1_dim = 500\n",
    "        h2_dim = 500\n",
    "        self.fc1 = nn.Linear(4, h1_dim)\n",
    "        self.fc2 = nn.Linear(h1_dim,h2_dim)\n",
    "        self.fc3 = nn.Linear(h1_dim,h2_dim)\n",
    "        self.fc_last = nn.Linear(h2_dim, 4)\n",
    "\n",
    "    def forward(self,qqd):\n",
    "        x = F.softplus(self.fc1(qqd))\n",
    "        x = F.softplus(self.fc2(x))\n",
    "        x = F.softplus(self.fc3(x))\n",
    "        x = self.fc_last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T08:16:53.019585Z",
     "start_time": "2020-10-07T08:16:53.012054Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, trainloader, device, optimizer, scheduler, num_epoch, testloader):\n",
    "    losses=[]\n",
    "    lr=[]\n",
    "    for i in range(num_epoch):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "        for state, target in trainloader:\n",
    "            state = state.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad() # Clear gradients from the previous iteration\n",
    "            pred = model(state)\n",
    "            loss = criterion(pred, target) # Calculate the loss\n",
    "            running_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step() # Update trainable weights\n",
    "        scheduler.step()\n",
    "        losses.append(np.mean(running_loss))\n",
    "        lr.append([(g['lr']) for g in optimizer.param_groups])\n",
    "        evaluate(model, criterion, testloader, device, show_plots=True)\n",
    "        print(\"Epoch {} loss:{}\".format(i,np.mean(running_loss))) # Print the average loss for this epoch\n",
    "        [print(\"lr: \", g['lr']) for g in optimizer.param_groups]\n",
    "    return losses,lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T08:23:13.342321Z",
     "start_time": "2020-10-07T08:23:13.338180Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, loader, device, show_plots=False, num_plots=1): # Evaluate accuracy on validation / test set\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    MSEs = []\n",
    "    with torch.no_grad(): # Do not calculate gradient to speed up computation\n",
    "        for state, target in (loader):\n",
    "            state = state.to(device)\n",
    "            target = target.to(device)\n",
    "            pred = model(state)\n",
    "\n",
    "            MSE_error = criterion(pred, target)\n",
    "            MSEs.append(MSE_error.item())\n",
    "\n",
    "    Ave_MSE = np.mean(np.array(MSEs))\n",
    "    print(\"\\nAverage Evaluation MSE: {}\".format(Ave_MSE))\n",
    "    return Ave_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Double Pendulum Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
